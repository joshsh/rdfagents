

################################################################################
# TwitLogic dump

time sesamize dump -o nquads ~/demos/twitlogic/twitlogic-core/data twitlogic-dump.nq

archived dump:
	12920019 twitlogic-dump.nq
active dump::
	1529985 twitlogic-dump-new.nq
combined dump
	14450004 twitlogic-dump-combined.nq

scp -P 2002 twitlogic-dump-new.nq.gz josh@flux.franz.com:/data/tmp


################################################################################
# emacs

esc-x flux
esc-x load-ag422


################################################################################
# create the store

(in-package :db.agraph.user)  
(enable-!-reader)  
(enable-print-decoded t)
(create-triple-store "rdfagents-www2012" :catalog "testing" :port 10042)


################################################################################
# import tweets to AG


cd /home/josh/projects/franz/agraph/422/src/cl/src/agraph/lisp/agload/agload

# loading takes about 11 minutes
time ./agload -i nquads -e ignore -v -p 10042 -c testing rdfagents-www2012  /data/datasets/twitlogic/twitlogic-dump-combined.nq.gz | tee ~/rdfagents-www2012.out


################################################################################
# explore the data

;;(require :agraph)
(in-package :db.agraph.user)  
(enable-!-reader)  
(enable-print-decoded t)
(register-namespace "sioc" "http://rdfs.org/sioc/ns#")
(register-namespace "sioct" "http://rdfs.org/sioc/types#")
(register-namespace "foaf" "http://xmlns.com/foaf/0.1/")
(open-triple-store "rdfagents-www2012" :catalog "testing" :port 10042)


(defun for-all-tweets (visitor)
    (iterate-cursor (tr (get-triples :o !sioct:MicroblogPost :p !rdf:type))
        (funcall visitor (subject tr))))
	
(defun for-all-replies (visitor)
    (iterate-cursor (tr (get-triples :p !sioc:reply_of))
        (funcall visitor (subject tr))))
	
(defun count-replies ()
    (setq count 0)
    (for-all-tweets (lambda (tweet)
	(if (reply_of tweet) (setq count (+ 1 count)))))
    count)
        
(defun count-total-replies ()
    (count-cursor (get-triples :p !sioc:reply_of)))

(defun count-total-topics ()
    (count-cursor (get-triples :p !sioc:topic)))
    
(defun count-total-links ()
    (count-cursor (get-triples :p !sioc:links_to)))

(defun count-total-users ()
    (count-cursor (get-triples :o !sioc:UserAccount :p !rdf:type)))
    
(defun count-total-people ()
    (count-cursor (get-triples :o !foaf:Agent :p !rdf:type)))
    
(defun reply-of (tweet)
    (setq original nil)
    (iterate-cursor (tr (get-triples :s tweet :p !sioc:reply_of))
	(setq original (object tr)))
    original)

(defun count-topics-of (tweet)
    (count-cursor (get-triples :s tweet :p !sioc:topic)))

(defun count-links-of (tweet)
    (count-cursor (get-triples :s tweet :p !sioc:links_to)))

(defun create-tweet-map ()
    (defparameter *tweet-map* (db.agraph.utility::make-upi-hash-table))
    (setq count 0)
    (for-all-tweets (lambda (tweet)
        (if (not (gethash tweet *tweet-map*))
	    (let ((foo 0))
	        (setq count (+ 1 count))
	        (setf (gethash tweet *tweet-map*) count))))))

(defun tweet-id (tweet)
    (gethash tweet *tweet-map*))
;;    (let ((s (part->value tweet)))
;;        (if (string= (subseq s 0 43) "http://twitlogic.fortytwo.net/post/twitter/")
;;	    (subseq s 43)
;;	    "unidentified")))

(defun generate-table ()
    (format t "topics,links,tweet,replyof~%")
    (for-all-tweets (lambda (tweet) (let (
        (id (tweet-id tweet))
	(topics (count-topics-of tweet))
	(links (count-links-of tweet))
	(rep (reply-of tweet)))
	    (format t "~d,~d,~d,~d,~a~%" (depth tweet) topics links id
	        (if rep (write-to-string (tweet-id rep)) ""))))))

(defun depth (tweet)
    (let ((d (gethash tweet *depth-map*)))
        (if d d
	    (let ((r (reply-of tweet)))
	        (let ((n
	            (if r (+ 1 (depth r)) 0)))
		    (setf (gethash tweet *depth-map*) n)
		    n)))))

(defun create-depth-map ()
    (defparameter *depth-map* (db.agraph.utility::make-upi-hash-table)))

(defun get-content (tweet)
    (setq content nil)
    (iterate-cursor (tr (get-triples :s tweet :p !sioc:content))
        (setq content (part->value (object tr))))
    content)

(defun starts-with (string prefix)
    (if (> (length prefix) (length string))
        nil
	(string= prefix (subseq string 0 (length prefix)))))

(defun count-total-retweets ()
    (setq count 0)
    (for-all-replies (lambda (tweet)
        (let ((content (get-content tweet)))
	    (if (starts-with content "RT")
	        (setq count (+ 1 count))))))
    count)
   
(defun print-retweets ()
    (for-all-replies (lambda (tweet)
        (let ((content (get-content tweet)))
	    (if (starts-with content "RT")
	        (format t "~d~%" (tweet-id tweet)))))))
    
# originally 14,220,487 triples
(triple-count)

# 1,481,653 tweets
(count-cursor (get-triples :o !sioct:MicroblogPost :p !rdf:type))

# 886,075 tweets, or 59.8%, are replies / retweets
(count-total-replies)

# 576,942 replies (or 65.11% of all replies) are actual retweets
(count-total-retweets)

# 634,148 sioc:topic links
(count-total-topics)

# 701,663 sioc:links_to links
(count-total-links)

# 379,060 user accounts
(count-total-users)

# 379,060 people (one per account)
(count-total-people)

(defparameter *minimum-stack-overflow-size* 10000)

(create-tweet-map)
(create-depth-map)
(with-open-file (*standard-output* "/tmp/www2012" :direction :output :if-exists :supersede)
    (generate-table))

(with-open-file (*standard-output* "/tmp/retweets" :direction :output :if-exists :supersede)
    (print-retweets))
    
(for-all-tweets (lambda (tweet)
    (if (eq 607521 (tweet-id tweet))
        (format t "~a~%" (part->value tweet)))))
	
# bash, on flux
gzip /tmp/www2012
gzip /tmp/retweets

# bash, locally
cd /Users/josh/data/rdfagents-www2012
scp -P 2002 josh@flux.franz.com:/tmp/www2012.gz .
scp -P 2002 josh@flux.franz.com:/tmp/retweets.gz .
gunzip www2012.gz
gunzip retweets.gz
cat www2012 | grep "[0-9]$" | sed 's/^[0-9]*,[0-9]*,//' | tr ',' '\t' > adjacency


################################################################################
# analysis in R

tweets <- read.csv(file("/Users/josh/data/rdfagents-www2012/www2012_clean"), header=TRUE)
retweets <- read.table(file("/Users/josh/data/rdfagents-www2012/retweets"))

# 1400262 total tweets
NROW(tweets)

# 804670 (57.47%) are replies
NROW(subset(tweets, nchar(replyof) > 1))

# 576942 (41.20%) are also retweets
NROW(retweets)

tmp <- data.frame(retweets, retweets)
retweet.tweets <- merge(tweets, tmp, by.x="tweet", by.y="V1")

adj <- data.frame(retweet.tweets$tweet, retweet.tweets$replyof)
write.table(adj, file("/tmp/adjacency"))

library(igraph)

# cat /tmp/adjacency | sed 's/^\"[0-9]*\" //' | sed 's/\"//' | sed 's/\"//'|more > /tmp/adjacency2
a <- read.graph(file("/tmp/adjacency2"), format="ncol", directed=TRUE)
# old: a <- read.graph(file("/Users/josh/data/rdfagents-www2012/adjacency"), format="ncol", directed=TRUE)

# 495553 retweets
NROW(E(a))
# 619727 tweets (44.26%) are in retweet chains
NROW(V(a))

c <- clusters(a)

# same as NROW(V(a))
sum(c$csize)

# largest thread is 1700 tweets
max(c$csize)

# On the first run, you will find tweet number 1189718 has 81390 in-links!
# This is the spurious tweet #http://twitlogic.fortytwo.net/post/twitter/, which needs to be removed
# On the second run, tweet number 607521 is found to have 1699 in-links (it's a star cluster)
# That is <http://twitlogic.fortytwo.net/post/twitter/16278399004>
# It was a funny remark by @Caterina (co-founder of Flickr and Hunch)
t1 <- table(adj[,1])
t2 <- table(adj[,2])
max(t2)
as.numeric(names(t2)[which.max(t2)])

# 124174 chains (so there are 4.99 tweets / chain on average)
c$no

# around 90% of tweets are in clusters of 43 or less
sizes <- -sort(-c$csize)
1 - sum(sizes[1:1500]) / NROW(tweets)

# tweets are replies of 0 or 1 other tweets, without exception
unique(degree(a, v=V(a), mode = c("out")))

# number of original tweets which are replied to: 124174
NROW(V(a)) - sum(degree(a, v=V(a), mode = c("out")))

# number of non-retweets: 823320
roots <- NROW(tweets) - NROW(retweets)

depth <- read.table("/Users/josh/data/rdfagents-www2012/depth")
h <- hist(depth[,2])
d <- c(roots, h$counts)

pdf("/tmp/tweet-depth.pdf")
barplot(d, log="y", space=0.5, names.arg=c(0:28),
    xlab="depth in retweet chain",
    ylab="# tweets at depth",
    cex.names=1.5, cex.lab=1.5, cex.axis=1.5)
dev.off()


d2 <- c(1:29)
dd <- d*d2

barplot(dd, log="y", space=0.5, names.arg=c(0:28),
    xlab="depth in retweet chain",
    ylab="# tweets at depth",
    cex.names=1.5, cex.lab=1.5, cex.axis=1.5)


# 40.27% are original tweets
roots / NROW(tweets)

# 57.11% are one-off replies or retweets (not themselves replied to or retweeted)
h$counts[1] / NROW(tweets)

# 38816 (2.62%) are retweets-of-retweets (or more)
# that's 6.73% of all retweets
sum(h$counts[2:100])


ind <- degree(a, v=V(a), mode = c("in"), loops = TRUE)

# replies tend *not* to have topics (tags): -0.1909449
cor(sign(tweets$topic), sign(nchar(as.vector(tweets$replyof))), method="pearson")

# replies tend to have links: 0.07311797
cor(sign(tweets$links), sign(nchar(as.vector(tweets$replyof))))

q <- merge(retweet.tweets, retweet.tweets, by.x="replyof", by.y="tweet")

# there is a 57.60% (strong) correlation between number of topics in an original tweet and a reply
cor(q$topics.x, q$topics.y, method="pearson")

# there is a 16.84% (low) correlation between number of links in an original tweet and a reply
cor(q$links.y, q$links.x, method="pearson")

qd <- merge(tweets, depth, by.x="tweet", by.y="V1")

# no correlation (among retweets) between tweet depth and number of hashtags
cor(qd$topics, qd$V2)

